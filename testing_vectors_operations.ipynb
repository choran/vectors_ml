{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RUymE2l9GZfO"
   },
   "source": [
    "##### Copyright 2018 The TensorFlow Hub Authors.\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "code",
    "id": "JMyTNwSJGGWg"
   },
   "outputs": [],
   "source": [
    "# Copyright 2018 The TensorFlow Hub Authors. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# =============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "co7MV6sX7Xto"
   },
   "source": [
    "# Universal Sentence Encoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MfBg1C5NB3X0"
   },
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://www.tensorflow.org/hub/tutorials/semantic_similarity_with_tf_hub_universal_encoder\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/hub/blob/master/examples/colab/semantic_similarity_with_tf_hub_universal_encoder.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/tensorflow/hub/blob/master/examples/colab/semantic_similarity_with_tf_hub_universal_encoder.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View on GitHub</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://storage.googleapis.com/tensorflow_docs/hub/examples/colab/semantic_similarity_with_tf_hub_universal_encoder.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://tfhub.dev/s?q=google%2Funiversal-sentence-encoder%2F4%20OR%20google%2Funiversal-sentence-encoder-large%2F5\"><img src=\"https://www.tensorflow.org/images/hub_logo_32px.png\" />See TF Hub models</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eAVQGidpL8v5"
   },
   "source": [
    "This notebook illustrates how to access the Universal Sentence Encoder and use it for sentence similarity and sentence classification tasks.\n",
    "\n",
    "The Universal Sentence Encoder makes getting sentence level embeddings as easy as it has historically been to lookup the embeddings for individual words. The sentence embeddings can then be trivially used to compute sentence level meaning similarity as well as to enable better performance on downstream classification tasks using less supervised training data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "63Pd3nJnTl-i"
   },
   "source": [
    "More detailed information about installing Tensorflow can be found at [https://www.tensorflow.org/install/](https://www.tensorflow.org/install/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "zwty8Z6mAkdV"
   },
   "outputs": [],
   "source": [
    "#@title Load the Universal Sentence Encoder's TF Hub module\n",
    "from absl import logging\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns\n",
    "\n",
    "module_url = \"https://tfhub.dev/google/universal-sentence-encoder/4\" #@param [\"https://tfhub.dev/google/universal-sentence-encoder/4\", \"https://tfhub.dev/google/universal-sentence-encoder-large/5\"]\n",
    "model = hub.load(module_url)\n",
    "print (\"module %s loaded\" % module_url)\n",
    "def embed(input):\n",
    "  return model(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2EIli4UPZVPB"
   },
   "source": [
    "# Create the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m43jrxkKXy97"
   },
   "outputs": [],
   "source": [
    "sample_sentences = [\"We scanned the skies with rainbow eyes\",\n",
    "                    \"We looked up into the sky\", \n",
    "                    \"It was raining and I saw a rainbow\", \n",
    "                    \"This sentence should not be similar to anything\", \n",
    "                    \"Erer blafgfgh jnjnjn ououou kjnkjnk\"]\n",
    "\n",
    "# Reduce logging output.\n",
    "logging.set_verbosity(logging.ERROR)\n",
    "\n",
    "sentence_embeddings = embed(sample_sentences)\n",
    "\n",
    "for i, sentence_embedding in enumerate(np.array(sentence_embeddings).tolist()):\n",
    "  print(\"Lyrics: {}\".format(sample_sentences[i]))\n",
    "  print(\"Embedding size: {}\".format(len(sentence_embedding)))\n",
    "  sentence_embedding_snippet = \", \".join(\n",
    "      (str(x) for x in sentence_embedding[:3]))\n",
    "  print(\"Embedding: [{}, ...]\\n\".format(sentence_embedding_snippet))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4MlSg6JjZb_P"
   },
   "source": [
    "# Get the vector norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xnlUSh9cXyzX"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "onGDse0uXyo2"
   },
   "outputs": [],
   "source": [
    "# Get the L1 norm\n",
    "for sentence, vector in zip(sample_sentences, sentence_embeddings):\n",
    "  l1 = norm(vector, 1)\n",
    "  print(f\"L1 norm of '{sentence}': is {l1:.4}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iHyZ7OSobnZm"
   },
   "outputs": [],
   "source": [
    "# Get the L2 norm\n",
    "for sentence, vector in zip(sample_sentences, sentence_embeddings):\n",
    "  l1 = norm(vector)\n",
    "  print(f\"L2 norm of '{sentence}': is {l1:.4}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XymeonC-jMTC"
   },
   "source": [
    "# Dot product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A61cJ3rqjR2z"
   },
   "outputs": [],
   "source": [
    "res = {}\n",
    "for sen in sample_sentences:\n",
    "    res[sen] = []\n",
    "\n",
    "for i, s1 in enumerate(sample_sentences):\n",
    "    for j, s2 in enumerate(sample_sentences):\n",
    "        dot_prod = np.dot(sentence_embeddings[i], sentence_embeddings[j])\n",
    "        res[s1].append(round(dot_prod, 3))\n",
    "    \n",
    "pd.DataFrame(res, index=[s for s in sample_sentences])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6LL4SMzZETfS"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uG0AKp-2lEFa"
   },
   "source": [
    "# Cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-ALIWQJXlGEP"
   },
   "outputs": [],
   "source": [
    "# This is an example of how to get cosine similarity with TF\n",
    "def get_cos_sim(sen1, sen2):\n",
    "  sts_encode1 = embed(tf.constant([sen1]))\n",
    "  sts_encode2 = embed(tf.constant([sen2]))\n",
    "  cosine_similarities = tf.reduce_sum(tf.multiply(sts_encode1, sts_encode2), axis=1)\n",
    "  return cosine_similarities\n",
    "\n",
    "res = {}\n",
    "for sen in sample_sentences:\n",
    "    res[sen] = []\n",
    "\n",
    "for i, s1 in enumerate(sample_sentences):\n",
    "    for j, s2 in enumerate(sample_sentences):\n",
    "        cosine = get_cos_sim(sample_sentences[i], sample_sentences[j])\n",
    "        res[s1].append(round(cosine.numpy()[0], 3))\n",
    "    \n",
    "pd.DataFrame(res, index=[s for s in sample_sentences])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R_YBrgkZluTs"
   },
   "outputs": [],
   "source": [
    "# This is an example of how to get cosine similarity with TF\n",
    "def get_norm_cos_sim(sen1, sen2):\n",
    "  sts_encode1 = tf.nn.l2_normalize(embed(tf.constant([sen1])), axis=1)\n",
    "  sts_encode2 = tf.nn.l2_normalize(embed(tf.constant([sen2])), axis=1)\n",
    "  cosine_similarities = tf.reduce_sum(tf.multiply(sts_encode1, sts_encode2), axis=1)\n",
    "  return cosine_similarities\n",
    "\n",
    "res = {}\n",
    "for sen in sample_sentences:\n",
    "    res[sen] = []\n",
    "\n",
    "for i, s1 in enumerate(sample_sentences):\n",
    "    for j, s2 in enumerate(sample_sentences):\n",
    "        cosine = get_norm_cos_sim(sample_sentences[i], sample_sentences[j])\n",
    "        res[s1].append(round(cosine.numpy()[0], 3))\n",
    "    \n",
    "pd.DataFrame(res, index=[s for s in sample_sentences])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TlWaMBiexDIB"
   },
   "source": [
    "# Nomalising a vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RCSbXWy4q7t8"
   },
   "outputs": [],
   "source": [
    "non_normed_vector = embed(tf.constant([sample_sentences[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I7nn6vwD39MA"
   },
   "outputs": [],
   "source": [
    "normed_vector = tf.nn.l2_normalize(embed(tf.constant([sample_sentences[0]])), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0NPqt505rVQ_"
   },
   "outputs": [],
   "source": [
    "non_normed_vector - normed_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([7, 6, 10])\n",
    "\n",
    "nrm = norm(x)\n",
    "print(f'Norm of vector {x} is {nrm}')\n",
    "normal_array = x/nrm\n",
    "print(f'The new normalized vecotr is {normal_array}')\n",
    "print(f'And the norm of this new vector should be 1.... {norm(normal_array)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oCBMXzcRylW-"
   },
   "source": [
    "# Dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pRAy0sg6sra-"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import plotly.express as px\n",
    "\n",
    "def get_3d_viz(X, sentences):\n",
    "    \n",
    "    pca = PCA(n_components=3)\n",
    "    pca_embed = pca.fit_transform(X)\n",
    "    \n",
    "    df = pd.DataFrame(columns=['x', 'y', 'z', 'word'])\n",
    "    df['x'], df['y'], df['z'], df['sentence'] = pca_embed[:,0], pca_embed[:,1], pca_embed[:,2], sentences\n",
    "    fig = px.scatter_3d(df, x='x', y='y', z='z', color='sentence')\n",
    "    return(fig)\n",
    "\n",
    "get_3d_viz(sentence_embeddings, sample_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u4AL5Auc0pA7"
   },
   "outputs": [],
   "source": [
    "get_3d_viz(sentence_embeddings, sample_sentences)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "RUymE2l9GZfO"
   ],
   "name": "Testing vector operations",
   "private_outputs": true,
   "provenance": [
    {
     "file_id": "https://github.com/tensorflow/hub/blob/master/examples/colab/semantic_similarity_with_tf_hub_universal_encoder.ipynb",
     "timestamp": 1617716309641
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
